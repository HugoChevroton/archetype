# -*- coding: utf-8 -*-
from django.utils.html import escape
import re
import os
import lxml.etree as ET
from lxml.etree import XMLSyntaxError
from django.shortcuts import render, render_to_response
import base64
from django.db.models.query import EmptyResultSet
psutil = None
try:
    import psutil
except Exception:
    pass

#_nsre = re.compile(ur'(?iu)([0-9]+|(?:\b[mdclxvi]+\b))')
REGEXP_ROMAN_NUMBER = re.compile(ur'(?iu)\b[ivxlcdm]+\b')
_nsre_romans = re.compile(ur'(?iu)(?:\.\s*)([ivxlcdm]+\b)')
_nsre = re.compile(ur'(?iu)([0-9]+)')


def total_seconds(timedelta):
    '''Backport timedelta.total_seconds from python 2.7 to python 2.6
    https://docs.python.org/2.7/library/datetime.html#datetime.timedelta.total_seconds
    '''
    return (timedelta.seconds + timedelta.days * 24 * 3600)


def is_roman_number(astring):
    return REGEXP_ROMAN_NUMBER.match(astring) is not None


def sorted_natural(l, roman_numbers=False, is_locus=False):
    '''Sorts l and returns it. Natural sorting is applied.'''
    ret = sorted(l, key=lambda e: natural_sort_key(e, roman_numbers, is_locus))
    # make sure the empty values are at the end
    for v in [None, u'', '']:
        if v in ret:
            ret.remove(v)
            ret.append(v)
    return ret


def natural_sort_key(s, roman_numbers=False, is_locus=False):
    '''
        Returns a list of tokens from a string.
        This list of tokens can be feed into a sorting function to come up with a natural sorting.
        Natural sorting is number-aware: e.g. 'word 2' < 'word 100'.

        If roman_numbers is True, roman numbers will be converted to ints.
        Note that there is no fool-proof was to detect roman numerals
        e.g. MS A; MS B; MS C. In this case C is a letter and not 500.
            MS A.ix In this case ix is a number
        So as a heuristic we only consider roman number if preceded by '.'

        If is_locus is True, 'face' will appear before 'dorse', etc.
    '''
    if s is None:
        s = ''

    if is_locus:
        s = re.sub(ur'(?i)\b(cover)\b', '50', s)
        s = re.sub(ur'(?i)\b(face|recto)\b', '100', s)
        s = re.sub(ur'(?i)\b(dorse|verso)\b', '200', s)
        s = re.sub(ur'(?i)\bseal\b', '300', s)

    if roman_numbers:
        while True:
            m = _nsre_romans.search(s)
            if m is None:
                break
            # convert the roman number into base 10 number
            number = get_int_from_roman_number(m.group(1))
            if number:
                # substition
                s = s[:m.start(1)] + str(number) + s[m.end(1):]

    return [int(text) if text.isdigit() else text.lower()
            for text in re.split(_nsre, s)]


def plural(value, count=2):
    '''
    Usage:
            {{ var|plural }}
            {{ var|plural:count }}

            If [count] > 1 or [count] is not specified, the filter returns the plural form of [var].
            Plural form is generated by sequentially applying the following rules:
                * convert 'y' at the end into 'ie'               (contry -> contrie)
                * convert 'ss' at the end into 'e'               (witness -> witnesse)
                * add a 's' at the end is none already there     (nation -> nations)
    '''

    if count is not None:
        try:
            count = int(float(count))
        except ValueError:
            pass
        except TypeError:
            pass
        try:
            count = len(count)
        except TypeError:
            pass

    words = value.split(' ')
    if len(words) > 1:
        # We got a phrase. Pluralise each word separately.
        ret = ' '.join([plural(word, count) for word in words])
    else:
        ret = value
        if ret in ['of']:
            return ret
        if count != 1:
            if ret in ['a', 'an']:
                return ''
            if ret[-1:] == 'y':
                ret = ret[:-1] + 'ie'
            if ret[-2:] == 'ss':
                ret = ret + 'e'
            if not ret[-1:] == 's':
                ret = ret + 's'
    return ret


def update_query_string(url, updates, url_wins=False):
    '''
        Replace parameter values in the query string of the given URL.
        If url_wins is True, the query string values in [url] will always supersede the values from [updates].

        E.g.

        >> _update_query_string('http://www.mysite.com/about?category=staff&country=UK', 'who=bill&country=US')
        'http://www.mysite.com/about?category=staff&who=bill&country=US'

        >> _update_query_string('http://www.mysite.com/about?category=staff&country=UK', {'who': ['bill'], 'country': ['US']})
        'http://www.mysite.com/about?category=staff&who=bill&country=US'

    '''
    show = url == '?page=2&amp;terms=%C3%86thelstan&amp;repository=&amp;ordering=&amp;years=&amp;place=&amp;basic_search_type=hands&amp;date=&amp;scribes=&amp;result_type=' and updates == 'result_type=manuscripts'

    ret = url.strip()
    if ret and ret[0] == '#':
        return ret

    from urlparse import urlparse, urlunparse, parse_qs

    # Convert string format into a dictionary
    if isinstance(updates, basestring):
        updates_dict = parse_qs(updates, True)
    else:
        from copy import deepcopy
        updates_dict = deepcopy(updates)

    # Merge the two query strings (url and updates)
    # note that urlparse preserves the url encoding (%, &amp;)
    parts = [p for p in urlparse(url)]
    # note that parse_qs converts u'terms=%C3%86thelstan' into u'\xc3\x86thelstan'
    # See http://stackoverflow.com/questions/16614695/python-urlparse-parse-qs-unicode-url
    # for the reaon behind the call to encode('ASCII')
    query_dict = parse_qs(parts[4].encode('ASCII'))
    if url_wins:
        updates_dict.update(query_dict)
        query_dict = updates_dict
    else:
        query_dict.update(updates_dict)

    # Now query_dict is our updated query string as a dictionary
    # Parse and unparse it again to remove the empty values
    query_dict = parse_qs(urlencode(query_dict, True))

    # remove temporary parameters __
    #query_dict = {k: v for k, v in query_dict.iteritems() if not k.startswith('__')}
    qd = query_dict
    query_dict = {}
    for k, v in qd.iteritems():
        if not k.startswith('__'):
            query_dict[k] = v

    # Convert back into a string
    parts[4] = urlencode(query_dict, True)

    # Place the query string back into the URL
    ret = urlunparse(parts)

    ret = escape(ret)

    if len(ret) == 0:
        ret = '?'

    # We mark this safe so django template renderer won't try to escape it a second time
    # This would generate something like this in the html output:
    # '?k1=v1&amp;amp;k2=v'
    from django.utils.safestring import mark_safe
    ret = mark_safe(ret)

    return ret


def get_str_from_call_stack(separator='; '):
    ret = ''
    import traceback
    import re
    tb = traceback.extract_stack()
    # ret = '; '.join(['%s (%s:%s)' % (call[2],
    # re.sub(ur'^.*[\\/]([^/\\]+)\.py$', ur'\1', call[0]), call[1]) for call
    # in tb])
    ret = separator.join(['%s (%s:%s)' % (call[2], call[0], call[1])
                          for call in tb])
    return ret


def urlencode(dict, doseq=0):
    ''' This is a unicode-compatible wrapper around urllib.urlencode()
        See http://stackoverflow.com/questions/3121186/error-with-urlencode-in-python

        dict: a dictionary of param name = values
        doseq: see urlliburlencode (if dicts values are sequences)
    '''
    import urllib
    d = {}
    for k, v in dict.iteritems():
        d[k] = []
        for v2 in dict[k]:
            if isinstance(v2, unicode):
                v2 = v2.encode('utf=8')
            d[k].append(v2)
    ret = urllib.urlencode(d, doseq)
    return ret


def get_tokens_from_phrase(phrase, lowercase=False):
    ''' Returns a list of tokens from a query phrase.

        Discard stop words (NOT, OR, AND)
        Detect quoted pieces ("two glosses")
        Remove field scopes. E.g. repository:London => London

        e.g. "ab cd" ef-yo NOT (gh)
        => ['ab cd', 'ef', 'yo', 'gh']
    '''
    ret = []

    if lowercase:
        phrase = phrase.lower()

    # Remove field scopes. E.g. repository:London => London
    phrase = re.sub(ur'(?u)\w+:', ur'', phrase)

    phrase = phrase.strip()

    # extract the quoted pieces
    for part in re.findall(ur'"([^"]+)"', phrase):
        ret.append(part)

    # remove them from the phrase
    phrase = re.sub(ur'"[^"]+"', '', phrase)

    # JIRA 358: search for 8558-8563 => no highlight if we don't remove non-characters before tokenising
    # * is for searches like 'digi*'
    phrase = re.sub(ur'(?u)[^\w*]', ' ', phrase)

    # add the remaining tokens
    if phrase:
        ret.extend([t for t in re.split(ur'\s+', phrase.lower().strip())
                    if t.lower() not in ['and', 'or', 'not']])

    return ret


def get_regexp_from_terms(terms, as_list=False):
    ''' input: list of query terms, e.g. ['ab', cd ef', 'gh']
        output: a regexp, e.g. '\bab\b|\bcd\b...
                if as_list is True: ['\bab\b', '\bcd\b']
    '''
    from whoosh.lang.morph_en import variations
    ret = []
    if terms:
        # create a regex
        for t2 in terms:
            for t in variations(t2):
                t = re.escape(t)

                if not t:
                    continue

                if 1:
                    if t[-1] in ['i', 'y']:
                        t = t[:-1] + '(y|i|ie|ies)'

                if 0:
                    if t[-1] == u's':
                        t += u'?'
                    else:
                        t += u's?'
        #             if len(t) > 1:
        #                 t += ur'?'
        #             t = ur'\b%ss?\b' % t
                t = ur'\b%s\b' % t

                # convert all \* into \W*
                # * is for searches like 'digi*'
                t = t.replace(ur'\*', ur'\w*')

                ret.append(t)

    if not as_list:
        ret = ur'|'.join(ret)

    return ret


def find_first(pattern, text, default=''):
    ret = default
    matches = re.findall(pattern, text)
    if matches:
        ret = matches[0]
    return ret


def get_int_from_roman_number(input):
    """
    From
    http://code.activestate.com/recipes/81611-roman-numerals/

    Convert a roman numeral to an integer.

    >>> r = range(1, 4000)
    >>> nums = [int_to_roman(i) for i in r]
    >>> ints = [roman_to_int(n) for n in nums]
    >>> print r == ints
    1

    >>> roman_to_int('VVVIV')
    Traceback (most recent call last):
    ...
    ValueError: input is not a valid roman numeral: VVVIV
    >>> roman_to_int(1)
    Traceback (most recent call last):
    ...
    TypeError: expected string, got <type 'int'>
    >>> roman_to_int('a')
    Traceback (most recent call last):
    ...
    ValueError: input is not a valid roman numeral: A
    >>> roman_to_int('IL')
    Traceback (most recent call last):
    ...
    ValueError: input is not a valid roman numeral: IL
    """
    if not isinstance(input, basestring):
        return None
    input = input.upper()
    nums = ['M', 'D', 'C', 'L', 'X', 'V', 'I']
    ints = [1000, 500, 100, 50, 10, 5, 1]
    places = []
    for c in input:
        if not c in nums:
            # raise ValueError, "input is not a valid roman numeral: %s" %
            # input
            return None
    for i in range(len(input)):
        c = input[i]
        value = ints[nums.index(c)]
        # If the next place holds a larger number, this value is negative.
        try:
            nextvalue = ints[nums.index(input[i + 1])]
            if nextvalue > value:
                value *= -1
        except IndexError:
            # there is no next place.
            pass
        places.append(value)
    sum = 0
    for n in places:
        sum += n
    return sum


def get_plain_text_from_html(html):
    '''Returns the unencoded text from a HTML fragment. No tags, no entities, just plain utf-8 text.
        Add spaces after </p>s.
    '''
    ret = html
    if ret:
        # JIRA 522
        ret = ret.replace('</p>', '</p> ')
        #
        from django.utils.html import strip_tags
        import HTMLParser
        html_parser = HTMLParser.HTMLParser()
        #ret = strip_tags(html_parser.unescape(ret))
        ret = html_parser.unescape(strip_tags(ret)).strip()
    else:
        ret = u''
    return ret


def set_left_joins_in_queryset(qs):
    #qs.query.promote_joins(qs.query.alias_map.keys(), True)
    qs.query.promote_joins(qs.query.alias_map.keys())


def get_str_from_queryset(queryset):
    # https://code.djangoproject.com/ticket/22973
    try:
        ret = unicode(queryset.query)
    except EmptyResultSet:
        ret = ur'SQL QUERY for EmptyResultSet'
    ret = re.sub(
        ur'(INNER|FROM|AND|OR|WHERE|GROUP|ORDER|LEFT|RIGHT|HAVING)', ur'\n\1', ret)
    ret = re.sub(ur'(INNER|AND|OR|LEFT|RIGHT)', ur'\t\1', ret)
    return ret.encode('ascii', 'ignore')


def remove_accents(input_str):
    '''Returns the input string without accented character.
        This is useful for accent-insensitive matching (e.g. autocomplete).
        >> remove_accents(u'c\u0327   \u00c7')
        u'c   c'
    '''
    import unicodedata
    # use 'NFD' instead of 'NFKD'
    # Otherwise the ellipsis \u2026 is tranformed into '...' and the output string will have a different length
    # return remove_combining_marks(unicodedata.normalize('NFKD',
    # unicode(input_str)))
    return remove_combining_marks(
        unicodedata.normalize('NFD', unicode(input_str)))


def remove_combining_marks(input_str):
    '''Returns the input unicode string without the combining marks found as 'individual character'
        >> remove_combining_marks(u'c\u0327   \u00c7')
        u'c   \u00c7'
    '''
    import unicodedata
    return u"".join([c for c in unicode(input_str)
                     if not unicodedata.combining(c)])


def write_file(file_path, content, encoding='utf8'):
    f = open(file_path, 'wb')
    if encoding:
        content = content.encode(encoding)
    f.write(content)
    f.close()


def get_bool_from_string(string):
    ret = False
    if str(string) in ['1', 'True', 'true', 'on', 'On']:
        ret = True
    return ret


def get_one2one_object(model, field_name):
    '''Returns model.field_name where field_name is a one2one relation.
        This function till return None if there no related object.
    '''
    ret = None

    if model:
        from django.core.exceptions import ObjectDoesNotExist
        try:
            getattr(model, field_name)
        except ObjectDoesNotExist as e:
            pass

    return ret

#-------------------------------------
#
#             XML
#
#-------------------------------------


def get_string_from_xml(xmltree, remove_root=False):
    '''Serialise the given XML node into a string.
        BEWARE: the method returns the TAIL, that is,
        the text that follows the element.
        E.g. '<a>some text</a> and its tail'

        WARNING: this function may generate entities
        for special chars.
        But get_unicode_from_xml() won't.
    '''
    ret = ET.tostring(xmltree)
    if remove_root:
        ret = ret.replace('<root>', '').replace('</root>', '')
    return ret


def get_unicode_from_xml(xmltree, encoding='utf-8',
                         text_only=False, remove_root=False):
    # if text_only = True => strip all XML tags
    # EXCLUDE the TAIL
    if text_only:
        return get_xml_element_text(xmltree)
    else:
        if hasattr(xmltree, 'getroot'):
            xmltree = xmltree.getroot()
        ret = ET.tostring(xmltree, encoding=encoding).decode('utf-8')
        if xmltree.tail is not None and ret[0] == '<':
            # remove the tail
            import regex as re
            ret = re.sub(ur'[^>]+$', '', ret)

        if remove_root:
            ret = ret.replace('<root>', '').replace('</root>', '')

        return ret


def get_xml_from_unicode(document, ishtml=False, add_root=False):
    # document = a unicode object containing the document
    # ishtml = True will be more lenient about the XML format
    #          and won't complain about named entities (&nbsp;)
    # add_root = True to surround the given document string with
    #         <root> element before parsing. In case there is no
    #        single containing element.

    if document and add_root:
        document = ur'<root>%s</root>' % document

    parser = None
    if ishtml:
        from io import StringIO
        parser = ET.HTMLParser()
        # we use StringIO otherwise we'll have encoding issues
        d = StringIO(document)
    else:
        from io import BytesIO
        d = BytesIO(document.encode('utf-8'))
    ret = ET.parse(d, parser)

    return ret


def get_xml_element_text(element):
    # returns all the text within element and its descendants
    # WITHOUT the TAIL.
    #
    # element is etree Element object
    #
    # '<r>t0<e1>t1<e2>t2</e2>t3</e1>t4</r>'
    # e = (xml.findall(el))[0]
    # e.text => t1
    # e.tail => t4 (! part of e1)
    # get_xml_element_text(element) => 't1t2t3'

    return ''.join(element.itertext())


def get_xslt_transform(source, template, error=None, remove_empty_xmlns=False):
    dom = get_xml_from_unicode(source)
    xslt = get_xml_from_unicode(template)
    try:
        transform = ET.XSLT(xslt)
    except Exception as e:
        for entry in e.error_log:
            print '%s: %s (line %s, %s)' % (entry.type_name, entry.message, entry.line, entry.column)
        raise e
    newdom = transform(dom)
    #print(ET.tostring(newdom, pretty_print=True))
    ret = newdom

    return ret


def is_xml_well_formed(xml_string):
    try:
        get_xml_from_unicode(xml_string, add_root=True)
        return True
    except ET.XMLSyntaxError as e:
        return False
    except ET.ParseError as e:
        return False


def strip_xml_tags(doc, xpath):
    '''Keep only the XML content of all the elements matching xpath'''
    temp_name = 'TOBEREMOVED'
    node = None
    for node in doc.xpath(xpath):
        node.tag = temp_name

    if node is not None:
        ET.strip_tags(doc, temp_name)


def remove_xml_elements(xml, xpath):
    ret = 0
    '''Remove all the elements matching xpath (and all their content)'''
    for element in xml.xpath(xpath):
        ret += 1
        element.getparent().remove(element)
    return ret

#-------------------------------------
#
#             INT & DATES
#
#-------------------------------------


def get_int(obj, default=0):
    '''Returns an int from an obj (e.g. string)
        If the conversion fails, returns default.
    '''
    try:
        ret = int(obj)
    except Exception:
        ret = default
    return ret


def get_int_from_request_var(request, var_name, default=0):
    obj = None
    if request:
        obj = request.GET.get(var_name, request.POST.get(var_name, None))
    return get_int(obj, default)


MAX_DATE_RANGE = [-5000, 5000]


def is_max_date_range(rng):
    return rng and rng[0] == MAX_DATE_RANGE[0] and rng[1] == MAX_DATE_RANGE[1]


def get_midpoint_from_date_range(astr=None, arange=None):
    '''
    Returns a numeric date which is the midpoint of a date range expressed in astr
    The midpoint is not always the average of the range, it is biased
    towards the date mentioned in the label.
    e.g. get_range_from_date('940x956') => 948
    e.g. get_range_from_date('Ca 1075') => 1075

    Returns None for unknown date
    '''
    ret = None

    if astr:
        astr = astr.strip()

    if arange is None:
        arange = get_range_from_date(astr)

    if is_max_date_range(arange):
        return ret

    # by default we take the middle point
    ret = (arange[1] + arange[0]) / 2

    if astr:
        # try harder... if we have a single date in the input we pick that one
        # Ca. 1090 => 1090
        patterns = [ur'(?i)^(?:c|ca)\.? (\d+)$']
        for pattern in patterns:
            s = re.sub(pattern, ur'\1', astr)
            if s != astr:
                ret = int(s)
                break

    return ret


def get_range_from_date(str):
    ret = get_range_from_date_simple(str)

    if str is not None and is_max_date_range(ret):
        # circa 1221 x circa 1247
        str = str.replace(u'×', u'x')
        if 'x' in str:
            parts = str.split('x')
            if len(parts) == 2:
                d0 = get_range_from_date_simple(parts[0])
                d1 = get_range_from_date_simple(parts[1])
                if not is_max_date_range(d0) or not is_max_date_range(d1):
                    ret = [d0[0], d1[1]]

    return ret


def get_range_from_date_simple(str):
    '''
    Returns a range of numeric dates from a string expression
    e.g. get_range_from_date('940x956') => [940, 956]
    e.g. get_range_from_date('Ca 1075') => [1070, 1080]
    '''
    ret = MAX_DATE_RANGE[:]

    if not str:
        return ret

    # print str

    # remove day
    # eg. Saturday 5 August 1245 => 5 August 1245
    str = re.sub(
        ur'(?iu)(monday|tuesday|wednesday|thursday|friday|saturday|sunday)', u'', str)

    # remove day month
    # eg. 11 November 1170 X 24 March 1201 => 1170 X 1201
    str = re.sub(ur'(?iu)((\d{1,2})\s)?(autumn|fall|summer|winter|spring|jan(\.|\s)|feb(\.|\s)|mar(\.|\s)|apr(\.|\s)|jun(\.|\s)|jul(\.|\s)|aug(\.|\s)|sept(\.|\s)|oct(\.|\s)|nov(\.|\s)|dec\.|january|february|march|april|may|june|july|august|september|october|november|december),?', u'', str)

    # expand s. => Saec.
    str = re.sub(ur'\bs\.\s', u'Saec. ', str)

    # early 12th => Saec. viii ex.
    # str = re.sub(ur'\bs\.\s', u'Saec. ', str)

    # convert circa => ca
    str = re.sub(ur'\bcirca\b', u'Ca', str)

    # expand c.1205 OR c 1205 => c. 1205
    str = re.sub(ur'\bc(?:\.|\s)(\d{4,4})', ur'c. \1', str)

    # expand c. => ca
    str = re.sub(ur'\bc\.\s', u'Ca ', str)

    # undated (early 1200s)
    str = re.sub(ur'^\s*undated\s+\((.*)\)\s*$', ur'\1', str)

    # remove prob.
    str = re.sub(ur'(prob.|probably|by)\s', '', str).strip()

    # remove ?, A.D.
    str = re.sub(ur'\?|A\.D\.', '', str).strip()

    # remove (...)
    str = re.sub(ur'\([^)]+\)', '', str).strip()

    # 845 for 830 => 830
    str = re.sub(ur'.*\sfor\s', '', str).strip()

    # 1234 x => after 1234
    # x 1234 => before 1234
    str = re.sub(ur'^\s*x\s*(\d{1,4})\s*$', ur'before \1', str).strip()
    str = re.sub(ur'^(\d{1,4})\s*x\s*$', ur'after \1', str).strip()

    str = str.strip()

    # 1080
    if re.match(ur'\d+$', str):
        return [int(str), int(str)]

    # 1035/6 => (1035, 1036)
    m = re.match(ur'(\d+)/(\d+)$', str)
    if m:
        ret = [int(m.group(1)), int(m.group(1))]
        if len(m.group(2)) < len(m.group(1)):
            ret[1] = int(m.group(1)[0:-len(m.group(2))] + m.group(2))

    m = re.match(ur'(?iu)(before|after)\s(\d+)$', str)
    if m:
        if m.group(1) == 'before':
            ret[1] = int(m.group(2))
        else:
            ret[0] = int(m.group(2))

    # Saec. x/xi or xi in. [  980.0,  1030.0]
    parts = re.split(ur'\bor\b', str)
    if len(parts) == 1:
        parts = re.split(ur'and', str)
    if len(parts) > 1:
        # combine different dates
        #dates = [ret]
        ret = get_range_from_date(parts[0].strip())
        for part in parts[1:]:
            part = part.strip()
            if not part.lower().startswith('saec.') and str.lower().startswith('saec.'):
                part = 'Saec. ' + part
            # combine the dates
            reti = get_range_from_date(part)
            ret = [min(ret[0], reti[0]), max(ret[1], reti[1])]
        return ret

    # Ca 1075 [ 1070.0,  1080.0]
    # Ca 1086 [ 1080.0,  1090.0]
    m = re.match(ur'(?iu)ca\.?\s*(\d+)$', str)
    if m:
        n = int(m.group(1))
        str = 'Ca %sx%s' % (n - 5, n + 5)

    # 1066x1087 => [1066, 1087]
    # Ca 820x840 => [820, 840]
    m = re.match(ur'(?iu)(?:ca\s)?(\d+)\s*[-x\xd7]\s*(\d+)$', str)
    if m:
        ret = [int(m.group(1)), int(m.group(2))]

        # case for '950x68' => 950x968
        if len(m.group(2)) < len(m.group(1)):
            ret[1] = int(m.group(1)[0:-len(m.group(2))] + m.group(2))

        if str.lower().startswith('ca '):
            # Ca 1002x1023 [ 1000.0,  1025.0]
            ret[0] = ret[0] - (ret[0] % 5)
            if ret[1] % 5:
                ret[1] = ret[1] - (ret[1] % 5) + 5
    # 107    1080s    1080.0    1085.0    1090.0
    m = re.match(ur'(?iu)(\d+0)s$', str)
    if m:
        ret = [int(m.group(1)), int(m.group(1)) + 10]

    # Saec. x1
    m = re.match(ur'(?iu)Saec. ([ivx]+)(.*)$', str)
    if m:
        mod = m.group(2).strip()
        century = get_int_from_roman_number(m.group(1))
        ret = [(century - 1) * 100, century * 100]
        # Saec. x1/3 [  900.0,   933.0]
        m2 = re.match(ur'(\d)/(\d)$', mod)
        if m2:
            dur = 100.0 / int(m2.group(2))
            ret[1] = ret[0] + (int(m2.group(1)) * dur)
            ret[0] = ret[1] - dur

        # in./med./ex.
        # digipal_date is not consistent for "ex."
        # it can be the last 20 or 30 years
        # 139    Saec. viii ex.    780.0    790.0    800.0
        # 137    Saec. vii ex.    670.0    690.0    700.0
        # => take last 30 years
        ex_duration = 30
        if mod == 'ex.':
            ret[0] = ret[1] - ex_duration
        if mod == 'in.':
            ret[1] = ret[0] + ex_duration
        if mod == 'med.':
            ret[1] = ret[0] + 66
            ret[0] = ret[0] + 33

        # Saec. xi1 => 1000, 1050
        if mod == '1':
            ret[1] = ret[0] + 50
        if mod == '2':
            ret[0] = ret[0] + 50

        #Saec. x/xi [  980.0,  1020.0]
        m2 = re.match(ur'/([ivx]+)$', mod)
        if m2:
            century2 = get_int_from_roman_number(m2.group(1))
            if century2 == century + 1:
                ret = [ret[1] - 20, ret[1] + 20]

        # if m.group(2) == '':

    ret = [int(ret[0]), int(ret[1])]

    return ret


def get_all_files_under(root, file_types='fd', filters=[], extensions=[
], direct_children=False, can_return_root=False):
    '''Returns a list of absolute paths to all the files under root.
        root is an absolute path
        file_types = types of files to return: f for files, d for directories
        extensions = only files with those extension will be returned
        filters = only files with those keywords anywhere in the path will be returned
    '''
    import os
    ret = []
    root = root.rstrip(os.path.sep)
    to_process = [root]

    filters = get_dict_from_string(filters)
    extensions = get_dict_from_string(extensions)

    while to_process:
        path = to_process.pop(0)
        file_type = 'd' if os.path.isdir(path) else 'f'
        if (file_type in file_types) and \
            (can_return_root or path != root) and \
            (not filters or any([filter.lower() in path.lower() for filter in filters])) and \
                (not extensions or any([path.endswith('.' + ext.strip('.')) for ext in extensions])):
            ret.append(path)

        if file_type == 'd' and (path == root or not direct_children):
            for file_name in os.listdir(path):
                to_process.append(os.path.join(path, file_name))
    return ret


def get_cms_page_from_title(title):
    from mezzanine.pages.models import Page as MPage
    from django.utils.text import slugify
    for page in MPage.objects.filter(slug__iendswith=slugify(unicode(title))):
        return page
    return None


def get_cms_url_from_slug(title):
    page = get_cms_page_from_title(title)
    if page:
        return page.get_absolute_url()
    from django.utils.text import slugify
    return u'/%s' % slugify(unicode(title))


def remove_param_from_request(request, key):
    ret = request
    # print dir(ret.GET)
    ret.GET = ret.GET.copy()
    if 'jx' in ret.GET:
        del ret.GET['jx']
    ret.META = ret.META.copy()
    ret.META['QUERY_STRING'] = re.sub(
        ur'\Wjx=1($|&|#)', ur'', ret.META.get('QUERY_STRING', ''))
    return ret


def read_file(filepath):
    import codecs
    f = codecs.open(filepath, 'r', "utf-8")
    ret = f.read()
    f.close()

    return ret


def get_dict_from_string(string, sep=',', keep_blanks=False):
    '''Return an array of string
        If the input is already an array, return it as is
        If the input is a string, split it around the commas
    '''
    ret = []
    if string:
        if isinstance(string, basestring):
            ret = string.split(sep)
        if isinstance(string, list) or isinstance(string, tuple):
            ret = string

    if not keep_blanks:
        ret = [r.strip() for r in ret]

    return ret


def get_normalised_path(path):
    ''' Turn the path and file names into something the image server won't complain about
        Extension is preserved.'''
    import os
    (file_base_name, extension) = os.path.splitext(path)
    file_base_name = re.sub(r'(?i)[^a-z0-9\\/]', '_', file_base_name)
    file_base_name = re.sub(r'_+', '_', file_base_name)
    file_base_name = re.sub(r'_?(/|\\)_?', r'\1', file_base_name)
    return file_base_name + extension


def add_keywords(obj, keywords='', remove=False):
    # add or remove Mezzanine keywords on a model instance
    # keywords is a comma separated list of keywords or an array
    ret = False
    keywords = get_dict_from_string(keywords)

    # read the keywords from the DB
    from mezzanine.generic.models import Keyword, AssignedKeyword
    existing_keywords = {}
    for kw in Keyword.objects.extra(where=["lower(title) in (%s)" % ', '.join([
                                    "'%s'" % kw.lower() for kw in keywords])]):
        existing_keywords[kw.title.lower()] = kw

    if remove:
        # TODO
        pass
    else:
        # add ids from assigned keywords
        for kw in [ak.keyword for ak in obj.keywords.all()]:
            existing_keywords[kw.title.lower()] = kw
        # create missing keywords
        for kw in keywords:
            if kw.lower() not in existing_keywords:
                print 'create %s' % kw
                existing_keywords[kw.lower()] = Keyword(title=kw)
                existing_keywords[kw.lower()].save()

        # now existing_keywords has all the requested keywords
        # assign them to the object
        from mezzanine.generic.fields import KeywordsField
        for field in [
                f for f in obj._meta.virtual_fields if f.__class__ == KeywordsField]:
            field.save_form_data(obj, u','.join(
                [unicode(kw.id) for kw in existing_keywords.values()]))

    return ret


def expand_folio_range(frange, errors=None):
    '''
        Returns an array of locus from a folio range expression
        If the expression is not valid it return []
        E.g.
        input: '140r20-1r2'
        output: ['140r', '140v', '141r']
    '''
    ret = []

    if errors is None:
        errors = []

    import re
    match = re.match(ur'(\d+)(r|v)(\d+)?(?:-(?:(\d+)(r|v))?(\d+)?)?', frange)
    if match:
        # frange = '140r20-1r2'
        # match.groups() = ('140', 'r', '20', '1', 'v', '2')

        # => fs = [140, 1]
        fs = [match.group(1), match.group(4)]
        if fs[1] is None:
            fs[1] = fs[0]
        # => fs = [140, 141]
        fs[1] = fs[0][0:(len(fs[0]) - len(fs[1]))] + fs[1]
        fs = [int(f) for f in fs]

        # => ret = [140r, 140v, 141r, 141v]

        if fs[1] < fs[0]:
            errors.append(u'Unrecognised folio range: %s' % frange)
        else:
            for f in range(fs[0], fs[1] + 1):
                ret.append('%sr' % f)
                ret.append('%sv' % f)

            # => ret = [140r, 140v, 141r]
            if match.group(2) == 'v':
                ret.pop(0)
            s = match.group(5) or match.group(2)
            if s == 'r':
                ret.pop()

    return ret


def is_model_visible(model, request):
    ''' Returns True if <model> is visible to the user.
    Based on setting.py:MODELS_PUBLIC and MODELS_PRIVATE.
    Note that it is NOT based on user/group permissions.
    If request is not provided we assume public user
    If request == True, returns true
    '''

    if request == True:
        return True

    if not model:
        return False

    # resolve model instance -> model
    from django.db.models.base import ModelBase
    meta = getattr(model, '_meta', None)
    if meta:
        model = getattr(model, 'model', meta)

    # resolve model -> string
    if isinstance(model, ModelBase):
        model = model.__name__

    # normalise model name
    model = ('%s' % model).lower()
    model = model.split('.')[-1]

    # check permissions from settings.py MODELS_PUBLIC|PRIVATE
    from mezzanine.conf import settings
    ret = (model in settings.MODELS_PUBLIC) or (
        (model in settings.MODELS_PRIVATE) and
        request and request.user and request.user.is_staff
    )

    return ret


def is_staff(request=None):
    # returns True if the request user is a staff
    if request == True:
        return True

    return request and request.user and is_user_staff(request.user)


def is_user_staff(user=None):
    # returns True if the request user is a staff
    if user == True:
        return True

    return user and user.is_staff


def raise_404(message=None, title=None):
    from django.http import Http404
    # Prior to 1.9 the production template would not receive any parameter
    # when calling django default Http404
    # See digipal.middleware.py.ErrorMiddleware
    raise Http404(message)


def request_invisible_model(model, request, model_label=None):
    # Raise 404 if the model is not visible
    if not is_model_visible(model, request):
        message = message = u'''You don't have access to this record type.'''
        if model_label:
            message = u'''You don't have access to %s records.''' % model_label
        raise_404(message)


def convert_xml_to_html(xml):
    ret = xml

    # todo:
    # () 4. add buttons to editor
    # () 5. display notes at the bottom of the desc

    ret = re.sub(
        ur'<c>', ur'<span data-dpt="record" data-dpt-model="character">', ret)

    for el in re.findall(ur'(?ui)<[^>]+>', xml):
        if re.search(ur'(?ui)</?(p|div|span)\b', el):
            continue

        nel = el
        nel = re.sub(ur'(?ui)([^\s>]+)(\s*=\s*")', ur'data-dpt-\1\2', nel)
        nel = re.sub(ur'(?ui)</([^\s>]+)', ur'</span', nel)
        nel = re.sub(ur'(?ui)<([^/\s>]+)', ur'<span data-dpt="\1"', nel)

        ret = ret.replace(el, nel)

    return ret


class ProgressBar(object):

    def __init__(self, amax=0.1, max_width=40):
        self.reset(amax=amax, max_width=max_width)

    def reset(self, amax=0.1, max_width=40):
        self.max = 1.0 * amax
        self.max_width = max_width
        self.width = 0
        print '_' * int(self.max_width)

    def complete(self):
        self.update(1, 1)
        print

    def update(self, pos=0.0, amax=None):
        import sys
        if amax:
            self.max = amax
        bar_width = int(1.0 * pos / self.max * self.max_width)
        ext = int(bar_width - self.width)
        if ext > 0:
            # print pos,self.max,ext
            sys.stdout.write('#' * ext)
            self.width = bar_width


def re_sub_fct(content, apattern, fct, are=None, show_bar=False):
    # Replace every occurrence of apattern in content with fct(match)
    # Return the resulting content
    if show_bar:
        bar = ProgressBar()
        bar.reset(len(content), 70)

    if not are:
        are = re
    pattern = are.compile(apattern)
    pos = 0
    if 0:
        while True:
            match = pattern.search(content, pos)
            if not match:
                break

            replacement = fct(match)
            content = ur'%s%s%s' % (content[0:match.start(
                0)], replacement, content[match.end(0):])
            pos = match.start(0) + len(replacement)
            if show_bar:
                bar.update(match.start(), len(content))
    else:
        content = pattern.sub(fct, content)

    if show_bar:
        bar.complete()

    return content


def dplog(message, level='DEBUG'):
    '''Log a debug message.
    Logged iff level >= settings.DIGIPAL_LOG_LEVEL
    '''
    import logging
    dplog = logging.getLogger('digipal_debugger')
    getattr(dplog, level.lower())(message)


def get_model_from_table_name(table_name):
    # BEWARE: not efficient!
    # Only use in command line scripts, not in site controllers/views
    ret = None

    from django.contrib.contenttypes.models import ContentType
    for ct in ContentType.objects.all():
        atable_name = '%s_%s' % (ct.app_label, ct.model)
        if atable_name == table_name:
            ret = ct.model_class()
            break

    return ret


def get_model_from_name(name):
    return get_models_from_names([name])


def get_models_from_names(names):
    # name = an array of model names
    # return a dictionary of model classes for the given model names
    # Only one class per name. In case of ambiguity, digipal app takes precedence. Otherwise it is undetermined.
    # The order of the returned list is undetermined.
    ret = {}

    from django.contrib.contenttypes.models import ContentType
    cts = ContentType.objects.filter(
        model__in=[name.strip().lower() for name in names]).order_by('app_label', 'model')
    for ct in cts:
        found_model = ret.get(ct.model, None)
        if found_model and found_model._meta.app_label == 'digipal':
            # In case of multiple matches priority is given to DigiPal models
            # Otherwise a random app will win
            continue
        model = ct.model_class()
        ret[ct.model] = model

    return ret.values()


def sql_select_dict(query, arguments=None):
    '''
        e.g.
        sql_select_dict('select * from table where x = %s', arguments=['value1'])
    '''
    from digipal.management.commands.utils import sqlSelect, fetch_all_dic
    from django.db import connections

    con = connections['default']
    cur = con.cursor()
    arguments = arguments or []
    cur.execute(query, arguments)

    desc = cur.description
    ret = [
        dict(zip([col[0] for col in desc], row))
        for row in cur.fetchall()
    ]

    cur.close()

    return ret


class MultiDict(dict):
    '''A multi-entries dictionary
        Behaves like a python dict where each value is a list of entries
        This class adds helpers functions to deal with this structure
        # {'key1': [e1, e2, e3, ...], ...}
    '''

    def add_entry(self, key, entry):
        if key not in self:
            self[key] = []
        if entry not in self[key]:
            self[key].append(entry)

    def get_entry_count(self):
        ret = 0
        for entries in self.values():
            ret += len(entries)
        return ret


def get_sortable_hash_value(obj):
    '''Returns a value that can be used as a key and can be sorted'''
    ret = unicode(obj)
    if isinstance(obj, list) and obj:
        ret = unicode(min(obj))
    return ret


import threading


class DPThread(threading.Thread):
    def __init__(self, fct, args, kwargs):
        threading.Thread.__init__(self)
        self.fct = fct
        self.args = args
        self.res = None
        self.kwargs = kwargs

    def run(self):
        self.res = self.fct(*self.args, **self.kwargs)


def run_in_thread(fct, args, kwargs):
    '''Runs one function is a separate thread'''
    thread = DPThread(fct, args, kwargs)
    thread.start()
    return thread


def run_in_thread_advanced(
        fct, args, kwargs, athreads=1, wait=False, print_results=False):
    '''Runs one function in multiple separate threads'''
    threads = []
    for i in range(0, athreads):
        threads.append(run_in_thread(fct, args, kwargs))

    if wait:
        from time import sleep
        while any([thread.is_alive() for thread in threads]):
            sleep(1)

    if print_results:
        for thread in threads:
            print repr(thread.res)

    return threads

# increment the value of an item in a counter dictionary
# {item: count, item: count}


def inc_counter(dic, item, count=1):
    dic[item] = dic.get(item, 0)
    dic[item] += count
    return dic[item]


def get_cache_key_from_string(s):
    '''Returns a base64 string from a hash of the given string <s>
        Hashed with SHA1
    '''
    import hashlib
    import base64
    hasher = hashlib.sha1()
    hasher.update(repr(s))
    return base64.b64encode(hasher.digest())


def get_mem():
    # return the memory used by this process in MB
    ret = 0
    if psutil:
        process = psutil.Process(os.getpid())
        ret = (process.memory_info().rss / 1024 / 1024)
    return ret


def gc_collect():
    # clear potentially huge query info in BEDUG mode
    # Should be quite fast
    from django import db
    db.reset_queries()
    # full garbage collection
    # this may be slow so avoid calling in a fast or large loop
    import gc
    gc.collect()


def get_plain_text_from_xmltext(xml_str, keep_links=False):
    '''Returns a plain text version of the XML <value>.
        For INDEXING PURPOSE.
        Strip tags, remove some abbreviations, ...
        Strip locations
       TODO: would be more reliable with pure XML transform
       but the content is not always well-formed so we have to
       resort to regexps.
    '''
    # Remove abbreviations and location elements
    import regex
    ret = xml_str

    if keep_links:
        ret = regex.sub(
            ur'<a[^>]+href="(.*?)"[^>]*>(.*?)</a>',
            ur'\2 [\1]',
            ret)

    ret = regex.sub(ur'<span data-dpt="abbr">.*?</span>', ur'', ret)
    ret = regex.sub(ur'<span data-dpt="location".*?</span>', ur'', ret)

    # Remove deleted elements
    # <span data-dpt="del" data-dpt-type="supplied">di</span>
    ret = regex.sub(ur'(?musi)<span data-dpt="del"[^>]*>[^<]*</span>', '', ret)

    ret = ret.replace(u'</p>', ' ')

    # Remove all tags
    import HTMLParser
    html_parser = HTMLParser.HTMLParser()
    from django.utils.html import strip_tags
    ret = html_parser.unescape(strip_tags(ret))

    # remove | (editorial line breaks) and other supplied signs <>
    ret = ret.replace(u'〈', '').replace(u'〉', '').replace(u'¦', '')

    # used between words in MOA
    ret = ret.replace(ur'', ';')

    # MS line breaks:
    ret = regex.sub(ur'(?musi)-\s*\|', u'#HY#', ret)
    # insert a CR to preserve rendering and also avoid joining words
    # accross the MS line break.
    ret = ret.replace(u'|', u'\r')
    # reunite hyphenated parts even when they are separated by spaces
    ret = regex.sub(ur'\s*#HY#\s*', u'', ret)

    ret = regex.sub(ur'(?musi)\s+', ' ', ret)

    return ret


def run_shell_command(command):
    ret = True
    try:
        os.system(command)
    except Exception as e:
        raise Exception('Error executing command: %s (%s)' % (e, command))
    finally:
        pass
    return ret


def get_python_path():
    # return the full path to python executable that runs this script

    # basic approach, get it directly from sys.
    # This is technically correct.
    # However one caveat is when systemwide python is called with the libs
    # from a virtualenv. In that case calling that python will not be able
    # to run django due to missing packages.
    import sys
    import os
    python_path = sys.executable

    # TODO
    # best approach would be to use the above and set the PYTHONPATH
    # but not easy and cross OS to pass sys.path within Popen()
    # If this works we don't need the code below to find virtualenv python
    lib_path = (os.pathsep).join(sys.path)

    # another is to find python within the virtual env
    if 0:
        # simple case, but again may not work if system-wide python
        # called with virtualenv libs... (e.g. EXON server)
        # In that case VIRTUAL_ENV is not set.
        virtualenv = os.environ.get('VIRTUAL_ENV')
        if virtualenv:
            ppath = os.path.join(virtualenv, 'bin', 'python')
            if os.path.exists(ppath):
                python_path = ppath

    if 1:
        # Here we try to find the virtualenv python in a directory above
        # the django package. This assumes that django runs from within a
        # virtualenv
        import django
        path = django.__file__
        while len(path) > 1:
            path = os.path.dirname(path)
            ppath = os.path.join(path, 'bin', 'python')
            if os.path.exists(ppath):
                python_path = ppath
                break

    return python_path


def call_management_command(command, *args, **kwargs):
    '''
    Execute a Django management command in a SEPARATE PROCESS.

    e.g. call_management_command('command', 'arg1', 'arg2', option1=val1, option2=val2)
    is executed as:
    python manage.py command arg1 arg2 --option1=val1 --option2=val2

    Note that the option names can be different from the internal names used
    by the management command. So not exactly the same as django call_command()

    Approach:
    We use Popen() to start another python process running the dhjango command.
    That process seems to inherit from our virtual env settings.
    And it will survive its parent.
    I.e. it's like doing a 'nohup ... &' from the command line

    Alternatives:
        * call command from this process: too long, browser will time out, web
            worker can be killed.
        * celery: best approach but introduces two new services (celery and redis
            , DB and cache brokers are not reliable)
        * p = multiprocessing.Process(fct); p.start() # fct => call_management()
            causes weird issues on Windows
            probably due concurrent modification of shared resources/variables.
        * os.fork(): not supported by Windows?. Approach is similar to previous
            one, anyway.
    '''

    # django manage command line
    command_django = '%s %s %s' % (
        command,
        ' '.join(args),
        (' '.join(['--%s=%s' % (k, v) for k, v in kwargs.iteritems()]))
    )

    # shell command line
    from mezzanine.conf import settings
    import sys

    python_path = get_python_path()

    command_shell = '%s %s %s' % (python_path, os.path.join(
        settings.PROJECT_ROOT, '..', 'manage.py'), command_django)

    if 1:
        # run the command in a child process, calling python
        from subprocess import Popen
        dplog('call command : %s' % command_shell)
        child_id = Popen(command_shell.split()).pid
        dplog('called command : %s | %s' % (child_id, command_shell))
    else:
        # fork doesn't work on WIndows
        # run the command in a child process, calling command directly from
        # this context
        from django.core.management import call_command
        from digipal.models import KeyVal
        from multiprocessing import Process
        from datetime import datetime

        def f(reindexes_str):
            KeyVal.set('k2.a', repr(datetime.now()))
            KeyVal.set('k2.b', reindexes_str)
            try:
                call_command('dpsearch', 'index_facets',
                             index_filter=reindexes_str)
            except Exception as e:
                KeyVal.set('k2.c', 'ERROR: %s' % repr(e))
            else:
                KeyVal.set('k2.c', repr(datetime.now()))
            exit()
        ##p = Process(target=f, args=(','.join(reindexes),))
        # p.start()
        # print p


def json_dumps(data):
    from datetime import datetime
    import json

    def json_serial(obj):
        """JSON serializer for objects not serializable by default json code"""
        if isinstance(obj, datetime):
            serial = obj.isoformat()
            return serial
        raise TypeError("Type not serializable")
    return json.dumps(data, default=json_serial)


def json_loads(data):
    #from datetime import datetime
    from django.utils.dateparse import parse_datetime
    import json

    # convert all dates in a list of dictionary from string to datetime
    def convert_dates(dic):
        if isinstance(dic, list):
            for i in range(0, len(dic)):
                if isinstance(dic[i], basestring):
                    # 2016-10-28T13:27:38.944298+00:00
                    v = dic[i]
                    if re.match(ur'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.*', v):
                        v = re.sub('(\+\d{2}):(\d{2})$', ur'\1\2', v)
                        dic[i] = parse_datetime(v)
                elif isinstance(dic[i], dict) or isinstance(dic[i], list):
                    convert_dates(dic[i])
        if isinstance(dic, dict):
            for k, v in dic.iteritems():
                if isinstance(v, basestring):
                    # 2016-10-28T13:27:38.944298+00:00
                    if re.match(ur'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.*', v):
                        v = re.sub('(\+\d{2}):(\d{2})$', ur'\1\2', v)
                        dic[k] = parse_datetime(v)
                elif isinstance(v, dict) or isinstance(v, list):
                    convert_dates(v)

    ret = None
    if data and data.strip():
        ret = json.loads(data)
        convert_dates(ret)

    return ret

########################
#
#     SERIALISATION
#
########################


def get_json_response(data):
    '''Returns a HttpResponse with the given data variable encoded as json'''
    from django.http.response import HttpResponse
    ret = HttpResponse(json_dumps(
        data), content_type='application/json; charset=utf-8', )
    ret['Access-Control-Allow-Origin'] = '*'
    return ret


def get_csv_response_from_rows(
        rows, charset='latin-1', headings=None, filename='response.csv'):
    # returns a http response with a CSV content created from rows
    # rows is a list of dictionaries

    from django.http import StreamingHttpResponse
    ret = StreamingHttpResponse(generate_csv_lines_from_rows(
        rows, encoding=charset, headings=headings), content_type="text/csv")
    ret['Content-Disposition'] = 'attachment; filename="%s"' % filename

    return ret


def write_rows_to_csv(file_path, rows, encoding=None, headings=None):
    '''
    rows: a list of records, each record is a dictionary with key/values
        all records must have the same keys

    output: write a csv file [file_path] with all the rows
    '''
    with open(file_path, 'wb') as csvfile:
        for line in generate_csv_lines_from_rows(
                rows, encoding=encoding, headings=headings):
            csvfile.write(line)


class Echo(object):
    def write(self, value):
        return value


def generate_csv_lines_from_rows(rows, encoding=None, headings=None):
    '''
    Returns a generator of lines of comma separated values
    from a list of rows
    each row is a dictionary: column_name => value
    '''
    encoding = encoding or 'Latin-1'
    if len(rows):
        import csv
        pseudo_buffer = Echo()
        # Can't use DictWriter b/c it .writerow() doesn't return anything.
        # Normal csv.writer does return the buffer.
        writer = csv.writer(pseudo_buffer)

        headings = headings or rows.keys()

        yield writer.writerow(headings)
        for row in rows:
            row_encoded = [unicode(row.get(k, '')).encode(
                encoding, 'replace') for k in headings]
            yield writer.writerow(row_encoded)


def read_all_lines_from_csv(
        file_path, ignore_incomplete_lines=False, encoding=None, same_as_above=None):
    '''
        Read a CSV file and returns an ARRAY where
        each entry correspond to a line in the file.
        It is assumed that the first line of the CSV
        contains the headings.

        Each entry in the returned array is a DICTIONARY
        where the keys are the column headings and the
        values in the corresponding line in the file.

        If ignore_incomplete_lines is True,
        ignore rows which have empty values in second and all following fields

        same_as_above = list of strings which mean that the value
            should be the same as in the above row
    '''
    ret = []

    import csv
    import chardet
    csv_path = file_path
    line_index = 0
    with open(csv_path, 'rb') as csvfile:
        if encoding is None:
            charres = chardet.detect(csvfile.read())
            csvfile.seek(0)
            if charres['confidence'] < 0.5:
                encoding = 'Latin-1'
            else:
                encoding = charres['encoding']
        print('encoding: %s' % encoding)

        csvreader = csv.reader(csvfile)

        columns = []

        line_last = None

        for line in csvreader:
            line_index += 1

            # skip some lines
            if ignore_incomplete_lines and len(''.join(line[1:]).strip()) == 0:
                continue

            # -> unicode
            line = [v.decode(encoding) for v in line]

            # heading line
            if not columns:
                for c in line:
                    c = re.sub(ur'[^a-z0-9]', '', c.lower())
                    if c and re.search(ur'^\d', c):
                        c = u'n%s' % c
                    columns.append(c)
                continue

            # 'same as' values
            if same_as_above and line_last:
                for i in range(0, len(line)):
                    if line[i] in same_as_above:
                        line[i] = line_last[i]

            # turn into dict
            rec = dict(zip(columns, line))
            rec['_line_index'] = line_index

            ret.append(rec)

            line_last = line

    return ret

########################


def get_short_uid(adatetime=None):
    # The time in milliseconds in base 36
    # e.g. 2016-11-12 23:14:29.337677+05:00 -> LMXOd7f65 (9 chars)
    # result is URL safe
    # If adatetime is None, uses now()
    from datetime import datetime
    b64 = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_.'
    BASE = len(b64)

    def num_encode(n):
        s = []
        while True:
            n, r = divmod(n, BASE)
            s.append(b64[r])
            if n == 0:
                break
        return ''.join(reversed(s))

    ret = adatetime or datetime.utcnow()
    ret = '%s%s%s%s%s%s' % (b64[ret.month], b64[ret.day], b64[ret.hour], b64[ret.minute],
                            b64[ret.second], num_encode(long('%s%s' % (ret.year - 2000, ret.microsecond))))
    #ret = ret.isoformat()
    # ret = long(re.sub(ur'\D', '', ret))
    #ret = str(ret)
    #ret = base64.b64encode(str(ret), 'ascii')
    # return parseInt((new Date()).toISOString().replace(/\D/g,
    # '')).toString(36);
    return ret


from datetime import datetime, timedelta, tzinfo

# A UTC class.
# Core Python has limited support time-zone aware datetimes
# We add UTC
# http://stackoverflow.com/a/2331635/3748764


class UTC(tzinfo):
    """UTC"""

    zero_offset = timedelta(0)

    def utcoffset(self, dt):
        return self.zero_offset

    def tzname(self, dt):
        return "UTC"

    def dst(self, dt):
        return self.zero_offset


utc = UTC()


def now():
    '''Returns UTC now datetime with time-zone'''
    return datetime.now(utc)


def cmp_locus(l1, l2):
    # compare two locuses
    # return -1 if locus1 < locus 2
    # 1 if >
    # 0 if =
    l1 = natural_sort_key(l1, 1, 1)
    l2 = natural_sort_key(l2, 1, 1)

    if l1 < l2:
        return -1
    elif l1 > l2:
        return 1

    return 0


def is_unit_in_range(unitid, ranges):
    ''' e.g. ('13a1', '1a1-10b3;45b1-45b2;60b4') => True
    '''
    ret = False

    ranges = ranges.strip()

    if not ranges:
        return True

    unit_keys = natural_sort_key(unitid)

    for range in ranges.split(','):
        parts = range.split('-')
        if len(parts) == 2:
            ret = (unit_keys >= natural_sort_key(parts[0])) and (
                unit_keys <= natural_sort_key(parts[1]))
        else:
            ret = unitid == parts[0]
        if ret:
            break

    return ret


def extract_file_from_zip(zip_path, file_path, output_path):
    '''Extract a single file from a ZIP into the given path.'''
    #cmd = 'unzip -p %s content.xml > %s' % (input_path, outfile)
    import zipfile

    with open(zip_path, 'rb') as fh:
        z = zipfile.ZipFile(fh)
        write_file(output_path, z.read(file_path), encoding=None)


def is_display_narrow(request):
    ret = False

    # TODO: test and make it more robust
    # print u'\n'.join([ur'%s = %s' % (k,v) for k,v in
    # request.META.iteritems()])
    ret = bool(re.search(ur'(?i)\b(mobile|opera mini|android|iphone|webos)\b',
                         request.META.get('HTTP_USER_AGENT')))

    return ret


def get_cache(name):
    from django.core.cache import caches
    ret = caches[name]
    return ret


def get_request_var(request, name, default=None):
    # avoid using REQUEST, deprecated in Django 1.9
    ret = request.GET.get(name, request.POST.get(name, default))
    return ret


def get_latest_docker_version(cached_days=1):
    '''
    Return build.__version__ from github master version.
    The value is cached for a day in the KeyVal table.
    '''
    from digipal.models import KeyVal
    import math
    import time
    now = time.time()

    from build import __version__ as ret

    key = 'get_latest_docker_version'
    info = KeyVal.getjs(key, {'last_checked': 0, 'version': ret})

    delta = (now - info['last_checked']) / 60.0 / 60 / 24
    if math.floor(delta) >= cached_days:
        info['last_checked'] = now
        content = ''
        version_url = 'https://raw.githubusercontent.com/kcl-ddh/digipal/master/build/__init__.py'
        import urllib2
        try:
            response = urllib2.urlopen(version_url)
            content = response.read()
        except Exception as e:
            pass

        if content:
            version = re.findall(ur"__version__\s*=\s*'([^']+)'", content)
            if version:
                info['version'] = version[0]

        KeyVal.setjs(key, info)

    return info['version']
